import os

import netCDF4
import numpy as np
import pytest

from aeolis import model


@pytest.fixture(scope="module")
def simulation_setup(request):
    dimension, case = request.param

    path_input_test_scenario = os.path.join(
        os.path.dirname(os.path.abspath(__file__)),
        "inputs",
        dimension,
        case,
    )
    path_config_file = os.path.join(path_input_test_scenario, "aeolis.txt")

    # Debug: Print the path to verify it
    print(f"Config file path: {path_config_file}")

    # Check if the file exists
    if not os.path.isfile(path_config_file):
        raise FileNotFoundError(f"Config file not found: {path_config_file}")

    # Initialize and run the model
    tmp_model = model.AeoLiSRunner(path_config_file)
    tmp_model.run()
    yield path_input_test_scenario, dimension, case
    # Delete aeolis.nc and aeolis.log file generated by the test
    os.remove(os.path.join(path_input_test_scenario, "aeolis.nc"))
    os.remove(os.path.join(path_input_test_scenario, "aeolis.log"))

    # Delete the model object
    del tmp_model


@pytest.mark.parametrize(
    "simulation_setup",
    [
        ("1D", "case1_small_waves"),
        ("1D", "case2_larger_waves"),
        ("1D", "case3_erosion_avalanching"),
    ],
    indirect=True,
    ids=[
        "1D_case1_small_waves",
        "1D_case2_larger_waves",
        "1D_case3_erosion_avalanching",
    ],  # these ids prints the dimension and case in the test name in the
    # pytest report making it easier to see the pass/fail status of each test # case.
)
class TestOutputFileGeneration:

    def test_netCDF_creation(self, simulation_setup):
        # Check if the netCDF file is created
        path_test_input, _, _ = simulation_setup
        assert os.path.isfile(
            os.path.join(path_test_input, "aeolis.nc")
        ), "The model should generate a netCDF file upon the completion of the simulation."

    def test_log_file_creation(self, simulation_setup):
        # Check if the log file is created
        path_test_input, _, _ = simulation_setup
        assert os.path.isfile(
            os.path.join(path_test_input, "aeolis.log")
        ), "The model should generate a log file upon the completion of the simulation."


@pytest.mark.parametrize(
    "simulation_setup",
    [
        ("1D", "case1_small_waves"),
        ("1D", "case2_larger_waves"),
        ("1D", "case3_erosion_avalanching"),
    ],
    indirect=True,
    ids=[
        "1D_case1_small_waves",
        "1D_case2_larger_waves",
        "1D_case3_erosion_avalanching",
    ],  # these ids prints the metal_adduct and output_type in the test name
    # in the pytest report, making it easier to see the pass/fail status of
    # each test case for each combination of dimensions and cases
)
class TestnetCDFContent:

    def test_array_shape(self, simulation_setup):
        # Check if the array shape is consistent
        path_test_input, dimension, case = simulation_setup
        with (
            netCDF4.Dataset(os.path.join(path_test_input, "aeolis.nc"), "r") as ds,
            netCDF4.Dataset(
                os.path.join(path_test_input, "output_expected.nc"), "r"
            ) as ds_expected,
        ):
            for variable in ds.variables.values():

                assert variable.shape == ds_expected.variables[variable.name].shape, (
                    f"Array shape of the paremeter '{variable.name}' is expected to"
                    " remain consistent across simulations for the same model"
                    f" parameter file for {dimension} {case}"
                )

    def test_array_dimension(self, simulation_setup):
        # Check if the array dimension is consistent
        path_test_input, dimension, case = simulation_setup
        with (
            netCDF4.Dataset(os.path.join(path_test_input, "aeolis.nc"), "r") as ds,
            netCDF4.Dataset(
                os.path.join(path_test_input, "output_expected.nc"), "r"
            ) as ds_expected,
        ):
            for variable in ds.variables.values():

                assert variable.ndim == ds_expected.variables[variable.name].ndim, (
                    f"Dimension of the parameter '{variable.name}' are expected to"
                    " remain consistent across simulations for the same model"
                    f" parameter file for {dimension} {case}"
                )

    def test_array_values(self, simulation_setup):
        # Check if the array values are consistent
        path_test_input, dimension, case = simulation_setup
        with (
            netCDF4.Dataset(os.path.join(path_test_input, "aeolis.nc"), "r") as ds,
            netCDF4.Dataset(
                os.path.join(path_test_input, "output_expected.nc"), "r"
            ) as ds_expected,
        ):
            for variable in ds.variables.values():
                # Collect the array values
                variable_value = variable[:]
                variable_value_expected = ds_expected.variables[variable.name][:]

                # Unmask the arrays to get the underlying data
                variable_value_data = np.ma.getdata(variable_value)
                variable_value_expected_data = np.ma.getdata(variable_value_expected)

                # Compare unmasked elements using numpy.allclose
                assert np.allclose(
                    variable_value_data,
                    variable_value_expected_data,
                ), (
                    f"Array values of the parameter '{variable.name}' are expected to"
                    " remain consistent across simulations for the same model"
                    f" parameter file for {dimension} {case}"
                )
